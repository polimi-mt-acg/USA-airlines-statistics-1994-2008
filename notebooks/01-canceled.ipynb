{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Apache Spark on this machine\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Dev mode: False when performing real analytics\n",
    "DEV = False\n",
    "\n",
    "# Build a Spark SQL Session for DataFrames\n",
    "master = 'local[2]'\n",
    "appName = 'Cancelled flights percentages'\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(appName) \\\n",
    "    .master(master) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting preprocessing of ../dataset/*.csv.bz2\n",
      "Preprocessing NOT performed.\n",
      "Preprocessed dataset already exists: ../dataset/preprocessed_dataset.parquet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from preprocessing_utils import *\n",
    "if DEV:\n",
    "    # DEV preprocessing\n",
    "    perform_DEV_dataset_preprocessing(spark)\n",
    "else:\n",
    "    # Production preprocessing\n",
    "    perform_dataset_preprocessing(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peprocessed dataset loaded.\n",
      "../dataset/preprocessed_dataset.parquet\n"
     ]
    }
   ],
   "source": [
    "# Load the parquet dataset\n",
    "if DEV:\n",
    "    # Load DEV dataset\n",
    "    df = load_DEV_preprocessed_dataset(spark)\n",
    "else:\n",
    "    # Load production dataset\n",
    "    df = load_preprocessed_dataset(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Month: integer (nullable = true)\n",
      " |-- DayofMonth: integer (nullable = true)\n",
      " |-- Cancelled: integer (nullable = true)\n",
      "\n",
      "+----+-----+----------+---------+\n",
      "|Year|Month|DayofMonth|Cancelled|\n",
      "+----+-----+----------+---------+\n",
      "|2007|    1|         1|        0|\n",
      "|2007|    1|         1|        0|\n",
      "|2007|    1|         1|        0|\n",
      "|2007|    1|         1|        0|\n",
      "|2007|    1|         1|        0|\n",
      "|2007|    1|         1|        0|\n",
      "|2007|    1|         1|        0|\n",
      "|2007|    1|         1|        0|\n",
      "|2007|    1|         1|        0|\n",
      "|2007|    1|         1|        0|\n",
      "+----+-----+----------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Keep only the dimensions we need\n",
    "df = df.select(df['Year'], df['Month'], df['DayofMonth'], df['Cancelled'])\n",
    "# Explore the data\n",
    "df.printSchema()\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|summary|           Cancelled|\n",
      "+-------+--------------------+\n",
      "|  count|            91469371|\n",
      "|   mean|0.021325903727926587|\n",
      "| stddev|  0.1444683695010413|\n",
      "|    min|                   0|\n",
      "|    max|                   1|\n",
      "+-------+--------------------+\n",
      "\n",
      "+-------+------------------+\n",
      "|summary|              Year|\n",
      "+-------+------------------+\n",
      "|  count|          91469371|\n",
      "|   mean|2001.5266289411786|\n",
      "| stddev| 4.332419506702069|\n",
      "|    min|              1994|\n",
      "|    max|              2008|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe('Cancelled').show()\n",
    "df.describe('Year').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse dates to datetime format\n",
    "import datetime\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import TimestampType, IntegerType\n",
    "\n",
    "make_date = lambda year, month, day : datetime.datetime(year, month, day) \n",
    "make_date = F.udf(make_date, TimestampType())\n",
    "\n",
    "\n",
    "#df = df.select(make_date(df['Year'], df['Month'], df['DayofMonth']).alias('Date'), 'Cancelled')\n",
    "df = df.select(df['Year'], df['Month'], df['DayofMonth'], df['Cancelled'])\n",
    "\n",
    "#df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+-----+\n",
      "|Year|Month|DayOfMonth|count|\n",
      "+----+-----+----------+-----+\n",
      "|2007|    1|        18|20815|\n",
      "|2007|    1|        19|20867|\n",
      "|2007|    9|        22|17136|\n",
      "|2006|    2|         3|19592|\n",
      "|2006|    8|        23|20386|\n",
      "|2004|    8|        14|18184|\n",
      "|2005|    1|        15|16826|\n",
      "|2005|   12|        25|16618|\n",
      "|2005|   12|         1|19246|\n",
      "|1995|    3|        20|15186|\n",
      "+----+-----+----------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "+----+-----+----------+-----+\n",
      "|Year|Month|DayOfMonth|count|\n",
      "+----+-----+----------+-----+\n",
      "|2007|    1|        18|  650|\n",
      "|2007|    1|        19|  511|\n",
      "|2007|    9|        22|  150|\n",
      "|2006|    2|         3|  413|\n",
      "|2006|    8|        23|  233|\n",
      "|2004|    8|        14|  863|\n",
      "|2005|    1|        15|  315|\n",
      "|2005|   12|         1|  286|\n",
      "|2005|   12|        25|  177|\n",
      "|1995|    3|        20|  232|\n",
      "+----+-----+----------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cancelled Flights\n",
    "cancelled_flights = df.filter(df['Cancelled'] == 1)\n",
    "\n",
    "# Number of flights per day \n",
    "all_flights_count = df.groupBy(['Year', 'Month', 'DayOfMonth']).count()\n",
    "cancelled_flights_count = cancelled_flights.groupBy(['Year', 'Month', 'DayOfMonth']).count()\n",
    "\n",
    "all_flights_count.show(10)\n",
    "cancelled_flights_count.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename count columns\n",
    "all_flights_count = all_flights_count.select('Year', 'Month', 'DayOfMonth', all_flights_count['count'].alias('total_count'))\n",
    "cancelled_flights_count = cancelled_flights_count.select('Year', 'Month', 'DayOfMonth', cancelled_flights_count['count'].alias('canceled_count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+-----------+--------------+\n",
      "|Year|Month|DayOfMonth|total_count|canceled_count|\n",
      "+----+-----+----------+-----------+--------------+\n",
      "|1994|   10|        28|      14847|            37|\n",
      "|1994|   12|        26|      14751|           159|\n",
      "|1995|    3|        20|      15186|           232|\n",
      "|1995|    5|        24|      14860|           199|\n",
      "|1996|    1|        19|      14799|          1049|\n",
      "|1996|    3|        25|      14910|           583|\n",
      "|1996|    6|         1|      13474|           244|\n",
      "|1996|   11|        28|      11529|            54|\n",
      "|1996|   12|         1|      14554|            83|\n",
      "|1997|    2|        16|      14335|           216|\n",
      "+----+-----+----------+-----------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Join the tables\n",
    "unified_dataset = all_flights_count \\\n",
    "                .join(cancelled_flights_count, ['Year', 'Month', 'DayOfMonth'])\n",
    "    \n",
    "unified_dataset.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unified_dataset = unified_dataset.withColumn(\"DailyCanceledFlightsPercentage\", ((F.col(\"canceled_count\") / F.col(\"total_count\"))* 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+------------------------------+\n",
      "|Year|Month|DayOfMonth|DailyCanceledFlightsPercentage|\n",
      "+----+-----+----------+------------------------------+\n",
      "|1994|   10|        28|           0.24920859432882064|\n",
      "|1994|   12|        26|             1.077893024201749|\n",
      "|1995|    3|        20|             1.527722902673515|\n",
      "|1995|    5|        24|             1.339165545087483|\n",
      "|1996|    1|        19|             7.088316778160686|\n",
      "|1996|    3|        25|             3.910127431254192|\n",
      "|1996|    6|         1|             1.810895057147098|\n",
      "|1996|   11|        28|             0.468384074941452|\n",
      "|1996|   12|         1|            0.5702899546516421|\n",
      "|1997|    2|        16|            1.5068015347052668|\n",
      "+----+-----+----------+------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unified_dataset = unified_dataset.select('Year', 'Month', 'DayOfMonth', 'DailyCanceledFlightsPercentage')\n",
    "unified_dataset.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+------------------------------+\n",
      "|Year|Month|DayOfMonth|DailyCanceledFlightsPercentage|\n",
      "+----+-----+----------+------------------------------+\n",
      "|2001|    9|        11|             85.48248871622008|\n",
      "|2001|    9|        13|             91.76825794690669|\n",
      "|2001|    9|        12|             99.99429744525547|\n",
      "+----+-----+----------+------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unified_dataset.filter(unified_dataset['DailyCanceledFlightsPercentage'] > 80).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store output Dataframe (or load it if already existing)\n",
    "final_dataset = '../dataset/canceled_analitics.parquet'\n",
    "\n",
    "path= Path(final_dataset)\n",
    "if not path.is_dir():\n",
    "    unified_dataset.write.mode('overwrite').save(final_dataset, format='parquet')\n",
    "unified_dataset = spark.read.load(final_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1994, 1, 20, 3.1078742428612633), (1994, 6, 6, 0.5723348503654668), (1994, 6, 9, 0.18612987729215497), (1994, 9, 23, 0.649395037254768), (1994, 10, 31, 1.561974011984111), (1995, 8, 14, 1.4915434811559463), (1996, 1, 2, 6.72579453067258), (1996, 11, 26, 1.6956980733702824), (1997, 3, 15, 1.4456593527555588), (1998, 1, 21, 2.581629944252721), (1998, 5, 20, 2.2865142323845076), (1999, 12, 27, 1.1671924290220819), (2000, 2, 20, 1.9454201567144016), (2000, 9, 3, 1.591450757284539), (2000, 9, 20, 2.0229222771967184), (2000, 10, 2, 2.3398015848256066), (2001, 3, 1, 2.9759872538978036), (2001, 5, 7, 2.5134751773049646), (2001, 5, 21, 2.6542649727767693), (2001, 10, 19, 0.39799629451725793), (2002, 1, 13, 1.0114335971855761), (2002, 2, 7, 0.9258624237020779), (2002, 9, 24, 1.0722956568653899), (2002, 11, 20, 0.799448656099242), (2003, 7, 8, 4.127447798333874), (2003, 8, 27, 1.408757138971988), (2004, 6, 15, 1.9102822580645162), (2005, 12, 13, 0.9238126290620584), (2005, 12, 21, 1.0135830417781437), (2006, 4, 30, 2.0856087793207467), (2006, 5, 1, 0.872366790582404), (2006, 10, 16, 3.6388468855177796), (2007, 4, 3, 3.4198560060629024), (2007, 4, 29, 0.5050505050505051), (2007, 7, 11, 3.998891762098264), (2007, 7, 30, 3.231300345224396), (2007, 11, 25, 0.649691874074428), (2008, 4, 15, 0.7806672965044006), (2008, 5, 7, 1.5073149105955372), (1994, 3, 28, 0.9745231797299179), (1994, 7, 13, 0.7550506768247058), (1994, 10, 14, 0.18916362653695445), (1994, 12, 15, 0.7499318243796018), (1995, 9, 8, 1.0559591068065644), (1995, 9, 20, 1.2057169951906794), (1996, 3, 19, 3.019526269878548), (1996, 11, 4, 1.5238852448154774), (1997, 4, 24, 1.6749868628481344), (1997, 11, 28, 1.0062049304041591), (1998, 4, 21, 1.9144144144144142), (1998, 10, 29, 1.6798418972332017), (1998, 10, 30, 1.5323906609667872), (1998, 12, 26, 0.8780561653167814), (1999, 3, 21, 1.1629507294247179), (1999, 7, 8, 2.4778200253485423), (1999, 12, 5, 0.9058578809635645), (2000, 2, 21, 1.7699115044247788), (2000, 4, 2, 1.051100680901699), (2000, 4, 27, 1.8867924528301887), (2001, 6, 23, 3.8665843113032734), (2001, 8, 16, 1.651828209866174), (2002, 10, 1, 0.8872333220453776), (2004, 1, 30, 1.6236087000919026), (2004, 3, 13, 0.3821434775056453), (2004, 6, 5, 0.5939338023296045), (2004, 8, 26, 0.9662769349695624), (2005, 1, 29, 14.848502746441438), (2005, 10, 4, 1.4697569248162803), (2006, 1, 26, 0.7183170856849667), (2006, 4, 17, 0.7157312799249715), (2006, 6, 17, 1.4277051981698914), (2006, 10, 14, 2.0981486923302968), (2006, 11, 2, 1.1315417256011315), (2007, 8, 18, 1.1629751017603214), (2007, 9, 30, 0.6630440201405853), (2008, 5, 24, 0.28115092420888915), (2008, 7, 3, 0.8664017998181036), (2008, 7, 4, 0.41890709015880956), (1994, 3, 22, 0.6623430384986891), (1994, 9, 13, 0.5129589632829373), (1995, 2, 12, 1.5283393872935371), (1995, 9, 13, 1.1714517876489707), (1996, 8, 10, 1.6726233023588277), (1996, 9, 9, 1.9448514719595043), (1996, 12, 9, 2.2319070258848392), (1996, 12, 14, 2.865916069600819), (1996, 12, 25, 2.327299593646103), (1997, 1, 8, 5.050970075633016), (1997, 5, 4, 0.8970168972950421), (1997, 8, 17, 3.45013841064074), (1997, 11, 15, 2.565655036706274), (1998, 5, 1, 2.0185922974767596), (1998, 8, 2, 2.009263043182128), (1998, 8, 19, 2.271248210334505), (1998, 12, 21, 2.9590834697217674), (1999, 1, 22, 7.681719866290883), (1999, 3, 5, 3.926141885325559), (1999, 3, 11, 1.7898832684824901), (1999, 9, 15, 7.414424655803967), (1999, 9, 29, 3.503224990514734)]\n"
     ]
    }
   ],
   "source": [
    "# Output a list of tuples of schema:\n",
    "# ('Data', 'Percentage')\n",
    "cancel_data = unified_dataset.rdd.map(tuple).collect()\n",
    "print(cancel_data[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hide warnings if there are any\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib ipympl\n",
    "\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leap years menagment\n",
    "leap_years= range(1996,2009,4)\n",
    "\n",
    "for i in range(1994, 2009):\n",
    "    if i not in leap_years:\n",
    "        newRow = spark.createDataFrame([[i, 2, 29, 0]])\n",
    "        unified_dataset = unified_dataset.union(newRow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pd_dataframe(years, df):\n",
    "    rows = df.filter(F.col('Year').isin(*years)) \\\n",
    "             .select('Year', 'Month', 'DayOfMonth', 'DailyCanceledFlightsPercentage') \\\n",
    "             .orderBy(['Year', 'Month', 'DayOfMonth']) \\\n",
    "             .collect()\n",
    "    \n",
    "    nb_years = len(years)\n",
    "    nb_days = 366\n",
    "    data = np.zeros((nb_days, nb_years))\n",
    "    for row in rows:\n",
    "        year = row[0] - years[0]\n",
    "        \n",
    "        \n",
    "        if(row[1]==2 and row[2]==29):\n",
    "            #29th of Februrary\n",
    "            day = 60\n",
    "        else:\n",
    "            date_format = str(row[0])\n",
    "            if row[1]<10 :\n",
    "                date_format = date_format + '0' + str(row[1])\n",
    "            else :\n",
    "                date_format = date_format + str(row[1])\n",
    "            if row[2]<10 :\n",
    "                date_format = date_format + '0' + str(row[2])\n",
    "            else :\n",
    "                date_format = date_format + str(row[2])\n",
    "            \n",
    "            date = pd.to_datetime(date_format, format='%Y%m%d')\n",
    "            new_year_day = pd.Timestamp(year=date.year, month=1, day=1)\n",
    "            day = (date - new_year_day).days\n",
    "        \n",
    "        pen = row[3] \n",
    "        \n",
    "        if day > 365: continue\n",
    "        data[day, year] = pen\n",
    "    columns = [str(y) for y in years]\n",
    "    indices = range(1, 367)\n",
    "    res = pd.DataFrame(data=data, columns=columns, index=indices)\n",
    "    return res\n",
    "#Check sul controllo di anni bisestili\n",
    "\n",
    "def plot_canceled_time_series(years, df,ax):\n",
    "    df = get_pd_dataframe(years, df)\n",
    "    title = 'Daily canceled flights percentage'\n",
    "    if df.empty:\n",
    "        print('No data')\n",
    "    else:\n",
    "        #print(df)\n",
    "        df.plot(title=title, grid=True, xticks=range(0, 367, 10), ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_df(years, df):\n",
    "    rows = df.filter(F.col('Year').isin(*years)) \\\n",
    "             .groupBy('Year') \\\n",
    "             .avg('DailyCanceledFlightsPercentage') \\\n",
    "             .withColumnRenamed('avg(DailyCanceledFlightsPercentage)', 'AverageDailyCanceledFlightsPercentage') \\\n",
    "             .select('Year', 'AverageDailyCanceledFlightsPercentage') \\\n",
    "             .collect()\n",
    "    \n",
    "    nb_years = len(years)\n",
    "    data = np.zeros(nb_years)\n",
    "    for row in rows:\n",
    "        year = row[0] - years[0]\n",
    "        avg_pen = row[1]\n",
    "        #Leap year            \n",
    "        if year not in leap_years:\n",
    "            avg_pen = avg_pen * (366/365)\n",
    "        data[year] = avg_pen \n",
    "    res = pd.DataFrame({'Canceled flights': data}, index=years)\n",
    "    return res\n",
    "\n",
    "def plot_average_canceled_flights(years, df, ax):\n",
    "    df = get_average_df( years, df)\n",
    "    title = 'Average canceled flights percentage'\n",
    "    if df.empty:\n",
    "        print('No data')\n",
    "    else:\n",
    "        #print(df)\n",
    "        df.plot.bar(title=title, rot=0 , ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ui_callback(years, df):\n",
    "    plt.figure(figsize=(15,12))\n",
    "    plt.clf()\n",
    "    ax = plt.subplot(211)\n",
    "    plot_canceled_time_series(range(years[0], years[1] + 1), df, ax)\n",
    "    \n",
    "    ax = plt.subplot(212)\n",
    "    plot_average_canceled_flights(range(years[0], years[1] + 1), df, ax)\n",
    "    \n",
    "    plt.subplots_adjust(top=0.92, bottom=0.08, left=0.10, right=0.95, hspace=0.25, wspace=0.35)\n",
    "    plt.show()\n",
    "\n",
    "# Years selection range\n",
    "years = range(1994, 2009)\n",
    "years = [(str(y), y) for y in years]\n",
    "years_w = widgets.SelectionRangeSlider(options=years,\n",
    "                                       index=(0, 2),\n",
    "                                       description='Years',\n",
    "                                       continuous_update=False)\n",
    "ui = widgets.HBox([years_w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9d7fc03a948458e96510f0869fd81cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(SelectionRangeSlider(continuous_update=False, description='Years', index=(0, 2), options=(('199…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec9bd3a8fde349c58e3c66803b609cf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out = widgets.interactive_output(ui_callback, {'years': years_w, 'df': widgets.fixed(unified_dataset)})\n",
    "display(ui, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Day number 60 is the 29th of February and the value there is valid only for leap years. For other years the percentage value is set to 0. In the average of course we take account of that and for the leap years it is computed on 366 days meanwhile for other years it is computed on 365 days."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
