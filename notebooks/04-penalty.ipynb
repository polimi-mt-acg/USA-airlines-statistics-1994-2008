{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airport weekly penalty for arrivals and departures delays \n",
    "\n",
    "In this notebook we are computing a weekly \"**penalty**\" score for each airport that depends on both the its incoming and outgoing\n",
    "flights. The score adds `0.5` for each incoming flight that is more than _15 minutes_ late, and `1` for\n",
    "each outgoing flight that is more than _15 minutes_ late.\n",
    "\n",
    "Formally speaking, let $w = \\{1, 2, \\ldots, 52 \\}$ be the _week number_ in a year $y$ and $x$ be a flight _leaving from_ or _arriving to_ $airport$ on week $w$ of year $year$. Then we compute the weekly penalties as the following:\n",
    "\n",
    "$$ ArrivalPenalty(f, y, w) = \\begin{cases} 0.5, & \\mbox{if } ArrDelay(f) > 15\\mbox{ seconds}\\\\\n",
    "                                           0, & \\mbox{otherwise}\n",
    "                                 \\end{cases}\n",
    "$$\n",
    "\n",
    "$$ DeparturePenalty(f, y, w) = \\begin{cases} 1, & \\mbox{if } DepDelay(f) > 15\\mbox{ seconds}\\\\\n",
    "                                             0, & \\mbox{otherwise}\n",
    "                                   \\end{cases}\n",
    "$$\n",
    "\n",
    "$$ WeeklyPenalty(airport, y, w) = \\sum_{f \\in Flights(airport, y, w)} ArrivalPenalty(f, y, w) + DeparturePenalty(f, y, w)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Apache Spark on this machine\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Dev mode: False when performing real analytics\n",
    "DEV = False\n",
    "\n",
    "### threads to be used to run spark worker nodes locally\n",
    "spark_local_threads = 4 \n",
    "\n",
    "# Build a Spark SQL Session for DataFrames\n",
    "master = 'local[{}]'.format(spark_local_threads)\n",
    "appName = 'Airport Weekly Penalty'\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(appName) \\\n",
    "    .master(master) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "Try to load the optimized *parquet* format data set. If *parquet* data set is not found, load full compressed data sets, reduce and save them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting preprocessing of ../dataset/*.csv.bz2\n",
      "Preprocessing NOT performed.\n",
      "Preprocessed dataset already exists: ../dataset/preprocessed_dataset.parquet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from preprocessing_utils import *\n",
    "if DEV:\n",
    "    # DEV preprocessing\n",
    "    perform_DEV_dataset_preprocessing(spark)\n",
    "else:\n",
    "    # Production preprocessing\n",
    "    perform_dataset_preprocessing(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peprocessed dataset loaded.\n",
      "../dataset/preprocessed_dataset.parquet\n"
     ]
    }
   ],
   "source": [
    "# Load the parquet dataset\n",
    "if DEV:\n",
    "    # Load DEV dataset\n",
    "    df = load_DEV_preprocessed_dataset(spark)\n",
    "else:\n",
    "    # Load production dataset\n",
    "    df = load_preprocessed_dataset(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Month: integer (nullable = true)\n",
      " |-- DayofMonth: integer (nullable = true)\n",
      " |-- DepTime: string (nullable = true)\n",
      " |-- ArrTime: string (nullable = true)\n",
      " |-- ArrDelay: integer (nullable = true)\n",
      " |-- DepDelay: integer (nullable = true)\n",
      " |-- Origin: string (nullable = true)\n",
      " |-- Dest: string (nullable = true)\n",
      "\n",
      "+----+-----+----------+-------+-------+--------+--------+------+----+\n",
      "|Year|Month|DayofMonth|DepTime|ArrTime|ArrDelay|DepDelay|Origin|Dest|\n",
      "+----+-----+----------+-------+-------+--------+--------+------+----+\n",
      "|2007|    1|         1|   1232|   1341|       1|       7|   SMF| ONT|\n",
      "|2007|    1|         1|   1918|   2043|       8|      13|   SMF| PDX|\n",
      "|2007|    1|         1|   2206|   2334|      34|      36|   SMF| PDX|\n",
      "|2007|    1|         1|   1230|   1356|      26|      30|   SMF| PDX|\n",
      "|2007|    1|         1|    831|    957|      -3|       1|   SMF| PDX|\n",
      "|2007|    1|         1|   1430|   1553|       3|      10|   SMF| PDX|\n",
      "|2007|    1|         1|   1936|   2217|      47|      56|   SMF| PHX|\n",
      "|2007|    1|         1|    944|   1223|      -2|       9|   SMF| PHX|\n",
      "|2007|    1|         1|   1537|   1819|      44|      47|   SMF| PHX|\n",
      "|2007|    1|         1|   1318|   1603|      -7|       3|   SMF| PHX|\n",
      "+----+-----+----------+-------+-------+--------+--------+------+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Keep only the dimensions we need\n",
    "df = df.select(df['Year'], df['Month'], df['DayofMonth'], df['DepTime'], \\\n",
    "               df['ArrTime'], df['ArrDelay'], df['DepDelay'], \\\n",
    "               df['Origin'], df['Dest'])\n",
    "# Explore the data\n",
    "df.printSchema()\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute weekly-penalty analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop entries with 'na' departure and arrival time\n",
    "df = df.dropna(subset=['DepTime', 'ArrTime'])\n",
    "\n",
    "# Parse dates to datetime format\n",
    "import datetime\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import TimestampType, IntegerType\n",
    "\n",
    "make_date = lambda year, month, day : datetime.datetime(year, month, day) \n",
    "make_date = F.udf(make_date, TimestampType())\n",
    "\n",
    "week_year = lambda date : date.isocalendar()[1]\n",
    "week_year = F.udf(week_year, IntegerType())\n",
    "\n",
    "df = df.select(make_date(df['Year'], df['Month'], df['DayofMonth']).alias('Date'), \\\n",
    "               'DepTime', 'ArrTime', 'ArrDelay', 'DepDelay', 'Origin', 'Dest')\n",
    "df = df.select('Date', week_year('Date').alias('WeekYear'), 'ArrDelay', 'DepDelay', 'Origin', 'Dest')\n",
    "# df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flights that are more than 15 minutes late\n",
    "left_late = df.filter(df['DepDelay'] > 15)\n",
    "arrived_late = df.filter(df['ArrDelay'] > 15)\n",
    "\n",
    "# Number of times per week an airport had a departure or an arrival more than 15 minutes late\n",
    "incoming_late = arrived_late.groupBy([F.year('Date').alias('Year'), 'WeekYear', arrived_late['Dest'].alias('Airport')]).count()\n",
    "outgoing_late = left_late.groupBy([F.year('Date').alias('Year'), 'WeekYear', left_late['Origin'].alias('Airport')]).count()\n",
    "\n",
    "# incoming_late.show(10)\n",
    "# outgoing_late.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Penalties on arrivals and departures\n",
    "incoming_factor = 0.5\n",
    "outgoing_factor = 1.0\n",
    "\n",
    "incoming_penalty = incoming_late.select('Year', 'WeekYear', 'Airport', (incoming_late['count'] * incoming_factor).alias('Penalty'))\n",
    "outgoing_penalty = outgoing_late.select('Year', 'WeekYear', 'Airport', (outgoing_late['count'] * outgoing_factor).alias('Penalty'))\n",
    "\n",
    "# incoming_penalty.show(10)\n",
    "# outgoing_penalty.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum up the penalties\n",
    "penalties = incoming_penalty \\\n",
    "                .unionAll(outgoing_penalty) \\\n",
    "                .groupBy('Year', 'WeekYear', 'Airport') \\\n",
    "                .sum('Penalty') \\\n",
    "                .withColumnRenamed('sum(Penalty)', 'WeeklyPenalty')\n",
    "\n",
    "# penalties.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store output Dataframe (or load it if already existing)\n",
    "final_dataset = '../dataset/penalty_analitics.parquet'\n",
    "\n",
    "path= Path(final_dataset)\n",
    "if not path.is_dir():\n",
    "    penalties.write.mode('overwrite').save(final_dataset, format='parquet')\n",
    "\n",
    "penalties = spark.read.load(final_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2007, 2, 'DTW', 784.5), (2007, 3, 'TUL', 209.0), (2007, 2, 'PSP', 96.0), (2007, 3, 'GRB', 67.0), (2007, 2, 'GTF', 12.5), (2007, 5, 'MLU', 27.0), (2007, 3, 'SJT', 13.5), (2007, 5, 'FAI', 16.0), (2007, 7, 'DAY', 148.0), (2007, 8, 'DAB', 30.0), (2007, 7, 'ROA', 50.0), (2007, 8, 'PFN', 28.5), (2007, 6, 'RFD', 5.5), (2007, 6, 'TRI', 3.0), (2007, 12, 'ABQ', 187.5), (2007, 12, 'OKC', 140.5), (2007, 10, 'CHA', 18.0), (2007, 11, 'PWM', 59.0), (2007, 10, 'CPR', 9.5), (2007, 10, 'SWF', 52.5), (2007, 17, 'IAD', 481.0), (2007, 17, 'CAE', 61.0), (2007, 14, 'IDA', 6.5), (2007, 14, 'IYK', 1.5), (2007, 16, 'APF', 2.5), (2007, 21, 'BTR', 56.0), (2007, 22, 'TLH', 12.0), (2007, 19, 'OGG', 32.0), (2007, 20, 'EKO', 1.5), (2007, 22, 'PIH', 2.0), (2007, 24, 'BWI', 1060.0), (2007, 26, 'PHX', 1712.5), (2007, 24, 'LGA', 1122.5), (2007, 25, 'FAR', 29.5), (2007, 26, 'SIT', 6.0), (2007, 26, 'KTN', 18.5), (2007, 30, 'BWI', 1145.0), (2007, 31, 'DAY', 88.0), (2007, 31, 'GSO', 109.0), (2007, 28, 'MYR', 71.5), (2007, 27, 'BZN', 19.0), (2007, 30, 'SCE', 2.0), (2007, 34, 'CLE', 603.5), (2007, 35, 'JAN', 81.5), (2007, 35, 'GJT', 16.0), (2007, 32, 'VLD', 8.5), (2007, 36, 'ISP', 39.0), (2007, 39, 'TLH', 16.5), (2007, 39, 'HNL', 139.0), (2007, 39, 'SPI', 10.0), (2007, 38, 'CIC', 4.5), (2007, 36, 'SIT', 12.5), (2007, 37, 'BET', 4.5), (2007, 39, 'OTZ', 3.5), (2007, 43, 'DCA', 481.5), (2007, 43, 'XNA', 91.0), (2007, 40, 'LGA', 769.0), (2007, 43, 'MSO', 5.0), (2007, 44, 'CPR', 4.0), (2007, 42, 'DLH', 12.0), (2007, 47, 'BRO', 10.5), (2007, 46, 'HLN', 5.0), (2007, 48, 'LNK', 22.0), (2007, 45, 'CHA', 16.5), (2007, 45, 'SOP', 3.0), (2007, 48, 'JNU', 11.5), (2007, 49, 'ONT', 229.5), (2007, 51, 'LGB', 102.0), (2007, 49, 'SUX', 3.0), (2007, 1, 'ELM', 3.0), (2007, 29, 'SIT', 16.5), (2007, 41, 'SJC', 351.5), (2008, 1, 'RSW', 252.0), (2008, 4, 'BOS', 602.5), (2008, 1, 'LRD', 5.0), (2008, 5, 'SLE', 7.5), (2008, 5, 'EWN', 3.5), (2008, 6, 'OMA', 223.5), (2008, 8, 'GUC', 6.0), (2008, 8, 'ABI', 13.0), (2008, 9, 'SUX', 3.0), (2008, 11, 'LBB', 74.0), (2008, 10, 'CHS', 149.0), (2008, 11, 'MDT', 43.0), (2008, 12, 'BIL', 12.0), (2008, 14, 'SPS', 12.5), (2008, 16, 'CHA', 10.5), (2008, 15, 'GSO', 113.5), (2008, 16, 'PNS', 25.0), (2008, 16, 'SBN', 13.5), (2008, 17, 'HDN', 2.0), (2008, 16, 'SPS', 7.0), (2008, 22, 'CVG', 308.5), (2008, 18, 'MSO', 4.0), (2008, 20, 'DHN', 8.5), (2008, 26, 'MSY', 275.5), (2008, 27, 'MDW', 288.0), (2008, 25, 'RIC', 115.0), (2008, 24, 'LIH', 32.0), (2008, 24, 'OXR', 4.0)]\n"
     ]
    }
   ],
   "source": [
    "# Output a list of tuples of schema:\n",
    "# ('Year', 'WeekYear', 'Airport', 'WeeklyPenalty')\n",
    "penalty_data = penalties.rdd.map(tuple).collect()\n",
    "print(penalty_data[:100])\n",
    "\n",
    "# Airports\n",
    "airports = penalties.select('Airport').distinct().orderBy('Airport').rdd.map(lambda x : x[0]).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization\n",
    "\n",
    "Analytics for airports weekly penalty are reported below.\n",
    "\n",
    "A **line plot** is used to display penalties as a time series. On the `x` axis the week number is reported, while on the `y` axis we show the weekly penalty.\n",
    "\n",
    "Moreover, a **bar plot** is chosen to display the *yearly average* weekly-penalty of a given airport."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hide warnings if there are any\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib ipympl\n",
    "\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weekly penalties over a year analytics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pd_dataframe(airport, years, df):\n",
    "    rows = df.filter(F.col('Airport') == airport) \\\n",
    "             .filter(F.col('Year').isin(*years)) \\\n",
    "             .select('Year', 'WeekYear', 'WeeklyPenalty') \\\n",
    "             .orderBy('Year', 'WeekYear') \\\n",
    "             .collect()\n",
    "    \n",
    "    nb_years = len(years)\n",
    "    nb_weeks = 52\n",
    "    data = np.zeros((nb_weeks, nb_years))\n",
    "    for row in rows:\n",
    "        year = row[0] - years[0]\n",
    "        week = row[1] - 1\n",
    "        pen = row[2]\n",
    "\n",
    "        if week > 51: continue\n",
    "        data[week, year] = pen\n",
    "    columns = [str(y) for y in years]\n",
    "    indices = range(1, 53)\n",
    "    res = pd.DataFrame(data=data, columns=columns, index=indices)\n",
    "    return res\n",
    "\n",
    "def plot_penalty_time_series(airport, years, df, ax):\n",
    "    df = get_pd_dataframe(airport, years, df)\n",
    "    title = '{} Airport - Weekly penalty'.format(airport)\n",
    "    if df.empty:\n",
    "        print('No data for airport {}'.format(airport))\n",
    "    else:\n",
    "        df.plot(title=title, grid=True, xticks=range(0, 53, 4), ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average penalty in a year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_df(airport, years, df):\n",
    "    rows = df.filter(F.col('Airport') == airport) \\\n",
    "             .filter(F.col('Year').isin(*years)) \\\n",
    "             .groupBy('Year') \\\n",
    "             .avg('WeeklyPenalty') \\\n",
    "             .withColumnRenamed('avg(WeeklyPenalty)', 'AveragePenalty') \\\n",
    "             .select('Year', 'AveragePenalty') \\\n",
    "             .collect()\n",
    "    \n",
    "    nb_years = len(years)\n",
    "    data = np.zeros(nb_years)\n",
    "    for row in rows:\n",
    "        year = row[0] - years[0]\n",
    "        avg_pen = row[1]\n",
    "        data[year] = avg_pen \n",
    "    res = pd.DataFrame({airport: data}, index=years)\n",
    "    return res\n",
    "\n",
    "def plot_average_penalty(airport, years, df, ax):\n",
    "    df = get_average_df(airport, years, df)\n",
    "    title = '{} Airport - Average Penalties'.format(airport)\n",
    "    if df.empty:\n",
    "        print('No data for airport {}'.format(airport))\n",
    "    else:\n",
    "        df.plot.bar(y=airport, title=title, rot=90, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ui_callback(airport, years, df):\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.clf()\n",
    "    ax = plt.subplot(121)\n",
    "    plot_penalty_time_series(airport, range(years[0], years[1] + 1), df, ax)\n",
    "    \n",
    "    ax = plt.subplot(122)\n",
    "    plot_average_penalty(airport, range(years[0], years[1] + 1), df, ax)\n",
    "    plt.show()\n",
    "\n",
    "# Years selection range\n",
    "years = range(1994, 2009)\n",
    "years = [(str(y), y) for y in years]\n",
    "years_w = widgets.SelectionRangeSlider(options=years,\n",
    "                                       index=(0, 2),\n",
    "                                       description='Years',\n",
    "                                       continuous_update=False)\n",
    "# Airport selection menu\n",
    "airports_w = widgets.Dropdown(options=airports,\n",
    "                              value=airports[0],\n",
    "                              description='Airport')\n",
    "\n",
    "ui = widgets.HBox([airports_w, years_w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8ffd58ad7704d919e93cac6106db10c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Airport', options=('ABE', 'ABI', 'ABQ', 'ABY', 'ACK', 'ACT', 'ACV', 'ACY'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62fe3f4ecbfc479899838f96e8947300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out = widgets.interactive_output(ui_callback, {'airport': airports_w, 'years': years_w, 'df': widgets.fixed(penalties)})\n",
    "display(ui, out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
