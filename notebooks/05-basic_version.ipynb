{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Additional data analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Per ogni aereoporto e per ogni settimana, percentuale di voli gestiti da ogni compagnia aerea\n",
    "\n",
    "2)Per ogni compagnia aerea, per ogni tratta, quanti voli fa annualmente su quella tratta\n",
    "Selezini comagnia aerea, anno.. per ogni tratta un bar plot con numero voli\n",
    "\n",
    "#Per ogni aeroporto la percentuale di voli gestiti da ciascuna comagnia aerea a settimana\n",
    "#Per ogni anno-compagnia aerea, per ogni tratta il valore di quante volte Ã© stata servita"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Initialize PySpark**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Apache Spark on this machine\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Dev mode: False when performing real analytics\n",
    "DEV = True\n",
    "\n",
    "### threads to be used to run spark worker nodes locally\n",
    "spark_local_threads = 2 \n",
    "\n",
    "# Build a Spark SQL Session for DataFrames\n",
    "master = 'local[{}]'.format(spark_local_threads)\n",
    "appName = 'Airport Weekly Penalty'\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(appName) \\\n",
    "    .master(master) \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- DEV mode ON ---------\n",
      "Starting preprocessing of ../dataset/1994.csv.bz2\n",
      "Preprocessing NOT performed.\n",
      "Preprocessed dataset already exists: ../dataset/preprocessed_dataset_1994.parquet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from preprocessing_utils import *\n",
    "if DEV:\n",
    "    # DEV preprocessing\n",
    "    perform_DEV_dataset_preprocessing(spark)\n",
    "else:\n",
    "    # Production preprocessing\n",
    "    perform_dataset_preprocessing(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- DEV mode ON ---------\n",
      "Peprocessed dataset loaded.\n",
      "../dataset/preprocessed_dataset_1994.parquet\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the parquet dataset# Load t \n",
    "if DEV:\n",
    "    # Load DEV dataset\n",
    "    df = load_DEV_preprocessed_dataset(spark)\n",
    "else:\n",
    "    # Load production dataset\n",
    "    df = load_preprocessed_dataset(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Cancelled: integer (nullable = true)\n",
      " |-- Origin: string (nullable = true)\n",
      " |-- Dest: string (nullable = true)\n",
      " |-- UniqueCarrier: string (nullable = true)\n",
      "\n",
      "+----+---------+------+----+-------------+\n",
      "|Year|Cancelled|Origin|Dest|UniqueCarrier|\n",
      "+----+---------+------+----+-------------+\n",
      "|1994|        0|   CLT| ORF|           US|\n",
      "|1994|        0|   CLT| ORF|           US|\n",
      "|1994|        0|   CLT| ORF|           US|\n",
      "|1994|        0|   CLT| ORF|           US|\n",
      "|1994|        0|   CLT| ORF|           US|\n",
      "|1994|        1|   CLT| ORF|           US|\n",
      "|1994|        0|   CLT| ORF|           US|\n",
      "|1994|        0|   CLT| ORF|           US|\n",
      "|1994|        0|   CLT| ORF|           US|\n",
      "|1994|        0|   CLT| ORF|           US|\n",
      "+----+---------+------+----+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Keep only the dimensions we need\n",
    "df = df.select(df['Year'], df['Cancelled'], \\\n",
    "               df['Origin'], df['Dest'],\\\n",
    "              df['UniqueCarrier'])\n",
    "# Explore the data\n",
    "df.printSchema()\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+\n",
      "|summary|UniqueCarrier|\n",
      "+-------+-------------+\n",
      "|  count|      5180048|\n",
      "|   mean|         null|\n",
      "| stddev|         null|\n",
      "|    min|           AA|\n",
      "|    max|           WN|\n",
      "+-------+-------------+\n",
      "\n",
      "+-------------+\n",
      "|UniqueCarrier|\n",
      "+-------------+\n",
      "|           UA|\n",
      "|           AA|\n",
      "|           NW|\n",
      "|           HP|\n",
      "|           TW|\n",
      "|           DL|\n",
      "|           US|\n",
      "|           AS|\n",
      "|           CO|\n",
      "|           WN|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe('UniqueCarrier').show()\n",
    "df.select('UniqueCarrier').distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Compute analytics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+----+-------------+-----+\n",
      "|Year|Origin|Dest|UniqueCarrier|Count|\n",
      "+----+------+----+-------------+-----+\n",
      "|1994|   GSO| CLT|           US| 2906|\n",
      "|1994|   PIT| BNA|           US| 1283|\n",
      "|1994|   MIA| DCA|           US|  475|\n",
      "|1994|   PIT| MHT|           US|  584|\n",
      "|1994|   ATL| DTW|           NW| 2028|\n",
      "|1994|   SDF| DTW|           NW| 1190|\n",
      "|1994|   BNA| MSP|           NW|  699|\n",
      "|1994|   AZO| MSP|           NW|  360|\n",
      "|1994|   ORD| SDF|           UA|  922|\n",
      "|1994|   ABE| MDT|           UA|  103|\n",
      "+----+------+----+-------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "# Drop cancelled flights\n",
    "df = df.drop(df['Cancelled'] == 1)\n",
    "\n",
    "df = df.withColumn(\"Count\", F.lit(1))\n",
    "\n",
    "df = df.groupBy(['Year', 'Origin', 'Dest', 'UniqueCarrier' ])                \\\n",
    "       .sum('Count')                               \\\n",
    "       .withColumnRenamed('sum(Count)', 'Count')    \n",
    "\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Should we keep the int value or use a percentage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store output Dataframe (or load it if already existing)\n",
    "final_dataset = '../dataset/uniqueCarrier_analitics.parquet'\n",
    "\n",
    "path= Path(final_dataset)\n",
    "if not path.is_dir():\n",
    "    df.write.mode('overwrite').save(final_dataset, format='parquet')\n",
    "df = spark.read.load(final_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1994, 'JAX', 'CLT', 'US', 2137), (1994, 'TRI', 'CLT', 'US', 1711), (1994, 'PIT', 'ELM', 'US', 1062), (1994, 'TPA', 'IND', 'US', 709), (1994, 'PNS', 'TPA', 'US', 144), (1994, 'CMH', 'MDW', 'US', 472), (1994, 'SYR', 'BOS', 'US', 1107), (1994, 'BWI', 'CHS', 'US', 457), (1994, 'LAX', 'SJC', 'WN', 4157), (1994, 'MCO', 'PBI', 'TW', 28)]\n"
     ]
    }
   ],
   "source": [
    "# Output a list of tuples of schema:\n",
    "# ('Data', 'Percentage')\n",
    "cancel_data = df.rdd.map(tuple).collect()\n",
    "print(cancel_data[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Visualization**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hide warnings if there are any\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib ipympl\n",
    "\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as dates\n",
    "import matplotlib.ticker as ticker\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueCarriers = ['UA', 'AA', 'NW', 'HP','TW', 'DL','US', 'AS', 'CO', 'WN']\n",
    "uniqueCarrier_values = [('UA', 0), ('AA', 1) , ('NW', 2), ('HP', 3),('TW', 4), ('DL', 5), ('US', 6), ('AS', 7),  ('CO', 8), ('WN', 9)]\n",
    "\n",
    "def get_index(carrier):\n",
    "    for uc in uniqueCarrier_values:\n",
    "        if uc[0] == carrier:\n",
    "              return uc[1]\n",
    "\n",
    "def get_count_df(airport_origin, airport_dest, years, df):\n",
    "    rows = df.filter(F.col('Year').isin(*years))\\\n",
    "             .filter(F.col('Origin') == airport_origin)\\\n",
    "             .filter(F.col('Dest') == airport_dest)\\\n",
    "             .select('UniqueCarrier', 'Count' ) \\\n",
    "                .collect()\n",
    "    \n",
    "    nb_uniqueCarriers = 10\n",
    "    data = np.zeros(nb_uniqueCarriers)\n",
    "    for row in rows:\n",
    "        uc = get_index(row[0])\n",
    "        sum_count = row[1]\n",
    "        data[uc] += sum_count \n",
    "        \n",
    "    columns = [str(c) for c in uniqueCarriers]\n",
    "    res = pd.DataFrame({'UniqueCarrier count': data}, index=uniqueCarriers)\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "def plot_count_carriers(airport_origin, airport_dest, years, df, ax):\n",
    "    df = get_count_df( airport_origin, airport_dest, years, df)\n",
    "    title = 'Unique Carrier count for Origin-Dest \\ Year'\n",
    "    if df.empty:\n",
    "        print('No data')\n",
    "    else:\n",
    "        df.plot.bar( title=title, rot=90, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Airports\n",
    "airports_origin = df.select('Origin').distinct().orderBy('Origin').rdd.map(lambda x : x[0]).collect()\n",
    "airports_dest = df.select('Dest').distinct().orderBy('Dest').rdd.map(lambda x : x[0]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ui_callback(airport_origin, airport_dest, years, df):\n",
    "    plt.figure(figsize=(9,12))\n",
    "    plt.clf()\n",
    "    ax = plt.subplot(211)\n",
    "    plot_count_carriers(airport_origin, airport_dest,range(years[0], years[1] + 1), df, ax)\n",
    "    \n",
    "    plt.subplots_adjust(top=0.92, bottom=0.08, left=0.10, right=0.95, hspace=0.25,\n",
    "                    wspace=0.35)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Years selection range\n",
    "years = range(1994, 2009)\n",
    "years = [(str(y), y) for y in years]\n",
    "years_w = widgets.SelectionRangeSlider(options=years,\n",
    "                                       index=(0, 2),\n",
    "                                       description='Years',\n",
    "                                       continuous_update=False)\n",
    "\n",
    "# Airport selection menu\n",
    "airports1_w = widgets.Dropdown(options=airports_origin,\n",
    "                              value=airports_origin[0],\n",
    "                              description='Airport_Origin')\n",
    "airports2_w = widgets.Dropdown(options=airports_dest,\n",
    "                              value=airports_dest[0],\n",
    "                              description='Airport_Dest')\n",
    "\n",
    "airports2_w = widgets.Dropdown(options=airports_dest,\n",
    "                              value=airports_dest[0],\n",
    "                              description='Airport_Dest')\n",
    "\n",
    "ui = widgets.HBox([airports1_w, airports2_w, years_w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "814ca435db2f407eadf4572ddc25f4e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Airport_Origin', options=('ABE', 'ABQ', 'ACK', 'ACY', 'ADQ', 'AGS', 'AKN'â¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74092bd23bc6412f89c0efa4424aeab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out = widgets.interactive_output(ui_callback, {'airport_origin': airports1_w,'airport_dest': airports2_w, 'years': years_w, 'df': widgets.fixed(df)})\n",
    "display(ui, out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
