{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Number of carries' flights done per year for each origin-dest pair**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Request** <br/>\n",
    "In this notebook we are counting the yearly number of flights provided by each carrier for each route. \n",
    "\n",
    "In the other notebooks different aspects of the dataset were analysed but no info about the carriers were retrieved so we decided to focus on that feature.<br/>\n",
    "We decided to keep the absolute value of flights managed by each carrier and not to use the percentage because we noticed a very deep variance of the possible results, some routes are much more covered than others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Initialize PySpark**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Apache Spark on this machine\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Dev mode: False when performing real analytics\n",
    "DEV = False\n",
    "\n",
    "### threads to be used to run spark worker nodes locally\n",
    "spark_local_threads = 2 \n",
    "\n",
    "# Build a Spark SQL Session for DataFrames\n",
    "master = 'local[{}]'.format(spark_local_threads)\n",
    "appName = 'Airport Weekly Penalty'\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(appName) \\\n",
    "    .master(master) \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting preprocessing of ../dataset/*.csv.bz2\n",
      "Preprocessing NOT performed.\n",
      "Preprocessed dataset already exists: ../dataset/preprocessed_dataset.parquet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from preprocessing_utils import *\n",
    "if DEV:\n",
    "    # DEV preprocessing\n",
    "    perform_DEV_dataset_preprocessing(spark)\n",
    "else:\n",
    "    # Production preprocessing\n",
    "    perform_dataset_preprocessing(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peprocessed dataset loaded.\n",
      "../dataset/preprocessed_dataset.parquet\n"
     ]
    }
   ],
   "source": [
    "# Load the parquet dataset# Load t \n",
    "if DEV:\n",
    "    # Load DEV dataset\n",
    "    df = load_DEV_preprocessed_dataset(spark)\n",
    "else:\n",
    "    # Load production dataset\n",
    "    df = load_preprocessed_dataset(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the dimensions we need\n",
    "df = df.select(df['Year'], df['Cancelled'],df['Origin'], df['Dest'], df['UniqueCarrier'])\n",
    "# Explore the data\n",
    "#df.printSchema()\n",
    "#df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.select('UniqueCarrier').distinct().show(30, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Compute analytics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+----+-------------+-----+\n",
      "|Year|Origin|Dest|UniqueCarrier|Count|\n",
      "+----+------+----+-------------+-----+\n",
      "|2007|   BNA| TPA|           WN| 1756|\n",
      "|2007|   LAX| OAK|           WN| 7496|\n",
      "|2007|   PHX| DTW|           WN|  667|\n",
      "|2007|   LAS| OKC|           YV|  123|\n",
      "|2007|   CMH| DCA|           OH|   91|\n",
      "|2007|   ORD| CVG|           OH| 1878|\n",
      "|2007|   BOS| BWI|           OH| 2562|\n",
      "|2007|   CVG| RIC|           OH|  628|\n",
      "|2007|   SMF| SLC|           OO|  990|\n",
      "|2007|   ACV| SFO|           OO| 2887|\n",
      "+----+------+----+-------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "# Drop cancelled flights\n",
    "df = df.drop(df['Cancelled'] == 1)\n",
    "\n",
    "df = df.withColumn(\"Count\", F.lit(1))\n",
    "\n",
    "df = df.groupBy(['Year', 'Origin', 'Dest', 'UniqueCarrier' ])                \\\n",
    "       .sum('Count')                               \\\n",
    "       .withColumnRenamed('sum(Count)', 'Count')    \n",
    "\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store output Dataframe (or load it if already existing)\n",
    "final_dataset = '../dataset/uniqueCarrier_analitics.parquet'\n",
    "\n",
    "path= Path(final_dataset)\n",
    "if not path.is_dir():\n",
    "    df.write.mode('overwrite').save(final_dataset, format='parquet')\n",
    "df = spark.read.load(final_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output a list of tuples of schema:\n",
    "# ('Data', 'Percentage')\n",
    "cancel_data = df.rdd.map(tuple).collect()\n",
    "#print(cancel_data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We create a dictionary where for each origin there are associated all the possible destinations\n",
    "origins = df.select(F.col('Origin')) \\\n",
    "                    .orderBy('Origin') \\\n",
    "                    .distinct() \\\n",
    "                    .rdd.map(lambda x : x[0]) \\\n",
    "                    .collect()  \n",
    "originDestDict= {}\n",
    "for origin in origins:\n",
    "    airports_temp = df.filter(F.col('Origin') == origin) \\\n",
    "                    .select(F.col('Dest')) \\\n",
    "                    .orderBy('Dest') \\\n",
    "                    .distinct() \\\n",
    "                    .rdd.map(lambda x : x[0]) \\\n",
    "                    .collect()    \n",
    "    originDestDict[origin] = airports_temp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store output Dictionary (or load it if already existing)\n",
    "import csv\n",
    "\n",
    "final_dict = '../dataset/origin_dest_dictionary.csv'\n",
    "\n",
    "path = Path(final_dict)\n",
    "\n",
    "if not path.is_file():\n",
    "    with open(final_dict, 'w') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        for key, val in originDestDict.items():\n",
    "            csv_writer.writerow([key, val])\n",
    "else:\n",
    "    for key, val in csv.reader(open(path)):\n",
    "        originDestDict[key] = val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Visualization**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hide warnings if there are any\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib ipympl\n",
    "\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as dates\n",
    "import matplotlib.ticker as ticker\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of all possible carriers\n",
    "uniqueCarriers = ['UA', 'AA', 'NW', 'EV', 'B6', 'HP','TW', 'DL', 'OO', 'F9', 'YV', 'TZ', 'US', 'AQ', 'MQ',\n",
    "                  'OH', 'HA', 'XE', 'DH', 'AS', 'FL', 'CO', 'WN', '9E']\n",
    "\n",
    "uniqueCarrier_values = [('UA', 0), ('AA', 1) , ('NW', 2), ('EV', 3), ('B6', 4), ('HP', 5),('TW', 6), ('DL', 7), ('OO', 8), \n",
    "                        ('F9', 9), ('YV', 10), ('TZ', 11), ('US', 12), ('AQ', 13), ('MQ', 14), ('OH', 15), ('HA', 16), \n",
    "                        ('XE', 17), ('DH', 18),('AS', 19), ('FL', 20), ('CO', 21), ('WN', 22), ('9E', 23)]\n",
    "\n",
    "def get_index(carrier):\n",
    "    for uc in uniqueCarrier_values:\n",
    "        if uc[0] == carrier:\n",
    "              return uc[1]\n",
    "\n",
    "def get_count_df(airport_origin, airport_dest, years, df):\n",
    "    rows = df.filter(F.col('Year').isin(*years))\\\n",
    "             .filter(F.col('Origin') == airport_origin)\\\n",
    "             .filter(F.col('Dest') == airport_dest)\\\n",
    "             .select('UniqueCarrier', 'Count' ) \\\n",
    "                .collect()\n",
    "    \n",
    "    nb_uniqueCarriers = 24\n",
    "    data = np.zeros(nb_uniqueCarriers)\n",
    "    for row in rows:\n",
    "        uc = get_index(row[0])\n",
    "        sum_count = row[1]\n",
    "        data[uc] += sum_count \n",
    "        \n",
    "    columns = [str(c) for c in uniqueCarriers]\n",
    "    res = pd.DataFrame({'UniqueCarrier count': data}, index=uniqueCarriers)\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "def plot_count_carriers(airport_origin, airport_dest, years, df, ax):\n",
    "    df = get_count_df( airport_origin, airport_dest, years, df)\n",
    "    title = 'Unique Carrier count for Origin-Dest and Year'\n",
    "    if df.empty:\n",
    "        print('No data')\n",
    "    else:\n",
    "        df.plot.bar( title=title, rot=90, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ui_callback(airport_origin, airport_dest, years, df):\n",
    "    plt.figure(figsize=(9,12))\n",
    "    plt.clf()\n",
    "    ax = plt.subplot(211)\n",
    "    plot_count_carriers(airport_origin, airport_dest,range(years[0], years[1] + 1), df, ax)\n",
    "    \n",
    "    plt.subplots_adjust(top=0.92, bottom=0.08, left=0.10, right=0.95, hspace=0.25,\n",
    "                    wspace=0.35)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Years selection range\n",
    "years = range(1994, 2009)\n",
    "years = [(str(y), y) for y in years]\n",
    "years_w = widgets.SelectionRangeSlider(options=years,\n",
    "                                       index=(0, 2),\n",
    "                                       description='Years',\n",
    "                                       continuous_update=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filled with the airports dest of airports_origin[0] a.k.a. 'ABE'\n",
    "airports_dx = df.filter(F.col('Origin') == 'ABE').select(F.col('Dest')).distinct().rdd.map(lambda x : x[0]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Airports\n",
    "airports_origin = df.select('Origin').distinct().orderBy('Origin').rdd.map(lambda x : x[0]).collect()\n",
    "airports_dest = df.select('Dest').distinct().orderBy('Dest').rdd.map(lambda x : x[0]).collect()\n",
    "\n",
    "\n",
    "# Airport selection menu\n",
    "airports1_w = widgets.Dropdown(options=airports_origin,\n",
    "                              value=airports_origin[0],\n",
    "                              description='Airport_Origin')\n",
    "airports2_w = widgets.Dropdown(options=airports_dx,\n",
    "                              value=airports_dx[0],\n",
    "                              description='Airport_Dest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = widgets.interactive_output(ui_callback, {'airport_origin': airports1_w,'airport_dest': airports2_w, 'years': years_w, 'df': widgets.fixed(df)})\n",
    "ui = widgets.HBox([airports1_w, airports2_w, years_w])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We allow to visualize in the Aiport_Dest only the airports that are destination of flights that start from the selected Airport_Origin.<br/>\n",
    "N.B.: if the graph is empty means that for the selected years that are no flights, selecting all the available years at least a bar will be visualized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "218122874cbe4f0486b302e79d8bf9c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Airport_Origin', options=('ABE', 'ABI', 'ABQ', 'ABY', 'ACK', 'ACT', 'ACV'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d80ded529511421c8fb8e7e594e7cddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def on_change(change):\n",
    "    # exclude the origin ariport and all the aiports with count 0 for all the carriers\n",
    "    global airports2_w\n",
    "    global df\n",
    "    airports_dx = originDestDict[change['new']]   \n",
    "    airports2_w.options = airports_dx\n",
    "    airports2_w.value = 'N/A' if not airports_dx else airports_dx[0]\n",
    "\n",
    "airports1_w.observe(on_change, 'value')\n",
    "display(ui, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
