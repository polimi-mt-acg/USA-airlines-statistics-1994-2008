{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Apache Spark on this machine\n",
    "import findspark\n",
    "findspark.init('/Users/giacomogregori/spark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Build a Spark SQL Session for DataFrames\n",
    "master = 'local[2]'\n",
    "appName = 'Weather delays percentages'\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(appName) \\\n",
    "    .master(master) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "full_data = '../dataset/*.csv.bz2'\n",
    "full_data_parquet = '../dataset/RITA_1994-2008.parquet'\n",
    "\n",
    "path = Path(full_data_parquet)\n",
    "# If reduced dataset is not found, load the full compressed dataset and reduce it.\n",
    "# This is going to take lot of time. Just wait.\n",
    "if not path.is_dir():\n",
    "    df = spark.read.csv(full_data, inferSchema=True, header=True, sep=',')\n",
    "    df.replace('NA', None) \\\n",
    "    .write \\\n",
    "    .save(full_data_parquet, format='parquet')\n",
    "\n",
    "# Load the reduced dataset\n",
    "df = spark.read.load(full_data_parquet, format='parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Year',\n",
       " 'Month',\n",
       " 'DayofMonth',\n",
       " 'DayOfWeek',\n",
       " 'DepTime',\n",
       " 'CRSDepTime',\n",
       " 'ArrTime',\n",
       " 'CRSArrTime',\n",
       " 'UniqueCarrier',\n",
       " 'FlightNum',\n",
       " 'TailNum',\n",
       " 'ActualElapsedTime',\n",
       " 'CRSElapsedTime',\n",
       " 'AirTime',\n",
       " 'ArrDelay',\n",
       " 'DepDelay',\n",
       " 'Origin',\n",
       " 'Dest',\n",
       " 'Distance',\n",
       " 'TaxiIn',\n",
       " 'TaxiOut',\n",
       " 'Cancelled',\n",
       " 'CancellationCode',\n",
       " 'Diverted',\n",
       " 'CarrierDelay',\n",
       " 'WeatherDelay',\n",
       " 'NASDelay',\n",
       " 'SecurityDelay',\n",
       " 'LateAircraftDelay']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+------------+------------+--------+-------------+-----------------+\n",
      "|               Date|WeekYear|CarrierDelay|WeatherDelay|NASDelay|SecurityDelay|LateAircraftDelay|\n",
      "+-------------------+--------+------------+------------+--------+-------------+-----------------+\n",
      "|2007-01-01 00:00:00|       1|           0|           0|       0|            0|                0|\n",
      "|2007-01-01 00:00:00|       1|           0|           0|       0|            0|                0|\n",
      "|2007-01-01 00:00:00|       1|           3|           0|       0|            0|               31|\n",
      "|2007-01-01 00:00:00|       1|          23|           0|       0|            0|                3|\n",
      "|2007-01-01 00:00:00|       1|           0|           0|       0|            0|                0|\n",
      "|2007-01-01 00:00:00|       1|           0|           0|       0|            0|                0|\n",
      "|2007-01-01 00:00:00|       1|          46|           0|       0|            0|                1|\n",
      "|2007-01-01 00:00:00|       1|           0|           0|       0|            0|                0|\n",
      "|2007-01-01 00:00:00|       1|          20|           0|       0|            0|               24|\n",
      "|2007-01-01 00:00:00|       1|           0|           0|       0|            0|                0|\n",
      "+-------------------+--------+------------+------------+--------+-------------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop cancelled flights\n",
    "df = df.drop(df['Cancelled'] == 1)\n",
    "\n",
    "\n",
    "# Parse dates to datetime format\n",
    "import datetime\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import TimestampType, IntegerType\n",
    "\n",
    "make_date = lambda year, month, day : datetime.datetime(year, month, day) \n",
    "make_date = F.udf(make_date, TimestampType())\n",
    "\n",
    "week_year = lambda date : date.isocalendar()[1]\n",
    "week_year = F.udf(week_year, IntegerType())\n",
    "\n",
    "df = df.select(make_date(df['Year'], df['Month'], df['DayofMonth']).alias('Date'), \\\n",
    "               'DayOfWeek', 'CarrierDelay', 'WeatherDelay','NASDelay','SecurityDelay','LateAircraftDelay')\n",
    "df = df.select('Date', week_year('Date').alias('WeekYear'), 'CarrierDelay', 'WeatherDelay','NASDelay','SecurityDelay','LateAircraftDelay')\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+-------------+\n",
      "|Year|WeekYear|weather_count|\n",
      "+----+--------+-------------+\n",
      "|2008|      35|         1413|\n",
      "|2005|      29|         3018|\n",
      "|2005|      49|         3513|\n",
      "|2007|       6|         2165|\n",
      "|2007|      52|         3271|\n",
      "|2005|       5|         1267|\n",
      "|2007|      28|         2940|\n",
      "|2005|      51|         1584|\n",
      "|2005|      25|         1653|\n",
      "|2008|      28|         3249|\n",
      "+----+--------+-------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+----+--------+-------------+\n",
      "|Year|WeekYear|general_count|\n",
      "+----+--------+-------------+\n",
      "|2008|      35|        19977|\n",
      "|2005|      29|        37064|\n",
      "|2005|      49|        34575|\n",
      "|2007|       6|        31743|\n",
      "|2007|      52|        47949|\n",
      "|2005|       5|        19279|\n",
      "|2007|      28|        42737|\n",
      "|2005|      51|        32616|\n",
      "|2005|      25|        26598|\n",
      "|2008|      28|        39097|\n",
      "+----+--------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Flights that have a WeatherDelay\n",
    "weather_delayed_flights = df.filter(df['WeatherDelay'] > 0)\n",
    "\n",
    "# Flights that have a Delay\n",
    "delayed_flights = df.filter((df['CarrierDelay'] > 0) | (df['WeatherDelay'] > 0) | (df['NASDelay'] > 0) | (df['SecurityDelay'] > 0) | (df['LateAircraftDelay'] > 0))\n",
    "\n",
    "# Number of times per week flights had a weather delay or a general delay  \n",
    "weather_delays = weather_delayed_flights.groupBy([F.year('Date').alias('Year'), 'WeekYear']).count()\n",
    "general_delays = delayed_flights.groupBy([F.year('Date').alias('Year'), 'WeekYear']).count()\n",
    "                            \n",
    "weather_delays = weather_delays.select('Year', 'WeekYear', weather_delays['count'].alias('weather_count'))\n",
    "general_delays = general_delays.select('Year', 'WeekYear', general_delays['count'].alias('general_count'))\n",
    "\n",
    "                            \n",
    "weather_delays.show(10)\n",
    "general_delays.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+-------------+-------------+\n",
      "|Year|WeekYear|weather_count|general_count|\n",
      "+----+--------+-------------+-------------+\n",
      "|2008|      35|         1413|        19977|\n",
      "|2005|      29|         3018|        37064|\n",
      "|2005|      49|         3513|        34575|\n",
      "|2005|       5|         1267|        19279|\n",
      "|2007|       6|         2165|        31743|\n",
      "|2007|      52|         3271|        47949|\n",
      "|2007|      28|         2940|        42737|\n",
      "|2005|      51|         1584|        32616|\n",
      "|2005|      25|         1653|        26598|\n",
      "|2005|      22|         2670|        26607|\n",
      "+----+--------+-------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the percentage\n",
    "percentage_weather_delays = weather_delays \\\n",
    "                .join(general_delays, [\"Year\",\"WeekYear\"])\n",
    "    \n",
    "percentage_weather_delays.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+-------------+-------------+--------------------+\n",
      "|Year|WeekYear|weather_count|general_count| WeeklyWeatherDelays|\n",
      "+----+--------+-------------+-------------+--------------------+\n",
      "|2008|      35|         1413|        19977| 0.07073134104219853|\n",
      "|2005|      29|         3018|        37064| 0.08142672134685949|\n",
      "|2005|      49|         3513|        34575| 0.10160520607375272|\n",
      "|2005|       5|         1267|        19279|   0.065719176305825|\n",
      "|2007|       6|         2165|        31743| 0.06820401348328765|\n",
      "|2007|      52|         3271|        47949|  0.0682183152933325|\n",
      "|2007|      28|         2940|        42737| 0.06879284928750264|\n",
      "|2005|      51|         1584|        32616| 0.04856512141280353|\n",
      "|2005|      25|         1653|        26598|0.062147529889465376|\n",
      "|2005|      22|         2670|        26607| 0.10034953207802458|\n",
      "+----+--------+-------------+-------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "percentage_weather_delays = percentage_weather_delays.withColumn(\"WeeklyWeatherDelays\", (F.col(\"weather_count\") / F.col(\"general_count\")))\n",
    "#['WeeklyWeatherDelays']= percentage_weather_delays['weather_count'] / percentage_weather_delays['general_count']\n",
    "percentage_weather_delays.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Year: int, WeekYear: int, WeeklyWeatherDelays: double]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage_weather_delays.select('Year','WeekYear','WeeklyWeatherDelays')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store output Dataframe (or load it if already existing)\n",
    "final_dataset = '../dataset/weather_analitics.parquet'\n",
    "\n",
    "path= Path(final_dataset)\n",
    "if not path.is_dir():\n",
    "    percentage_weather_delays.write.mode('overwrite').save(final_dataset, format='parquet')\n",
    "else:\n",
    "    percentage_weather_delays = spark.read.load(final_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output a list of tuples of schema:\n",
    "# ('Year', 'WeekYear', 'Percentage')\n",
    "weather_data = percentage_weather_delays.rdd.map(tuple).collect()\n",
    "print(weather_data[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hide warnings if there are any\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib ipympl\n",
    "\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pd_dataframe( years, df):\n",
    "    rows = df.filter(F.col('Year').isin(*years)) \\\n",
    "             .select('Year', 'WeekYear', 'WeeklyWeatherDelays') \\\n",
    "             .orderBy('Year', 'WeekYear') \\\n",
    "             .collect()\n",
    "    \n",
    "    nb_years = len(years)\n",
    "    nb_weeks = 52\n",
    "    data = np.zeros((nb_weeks, nb_years))\n",
    "    for row in rows:\n",
    "        year = row[0] - years[0]\n",
    "        week = row[1] - 1\n",
    "        per = row[2]\n",
    "\n",
    "        if week > 51: continue\n",
    "        data[week, year] = per\n",
    "    columns = [str(y) for y in years]\n",
    "    indices = range(1, 53)\n",
    "    res = pd.DataFrame(data=data, columns=columns, index=indices)\n",
    "    return res\n",
    "\n",
    "def plot_weather_time_series(years, df):\n",
    "    df = get_pd_dataframe(years, df)\n",
    "    title = 'Weekly weather delays percentage'\n",
    "    if df.empty:\n",
    "        print('No data')\n",
    "    else:\n",
    "        df.plot(title=title, grid=True, xticks=range(0, 53, 4), colormap='tab20c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_df(years, df):\n",
    "    rows = df.filter(F.col('Year').isin(*years)) \\\n",
    "             .groupBy('Year') \\\n",
    "             .avg('WeeklyWeatherDelays') \\\n",
    "             .withColumnRenamed('avg(WeeklyWeatherDelays)', 'AverageWeatherDelaysPercentage') \\\n",
    "             .select('Year', 'AverageWeatherDelaysPercentage') \\\n",
    "             .collect()\n",
    "    \n",
    "    nb_years = len(years)\n",
    "    data = np.zeros(nb_years)\n",
    "    for row in rows:\n",
    "        year = row[0] - years[0]\n",
    "        avg_pen = row[1]\n",
    "        data[year] = avg_pen \n",
    "    res = pd.DataFrame({airport: data}, index=years)\n",
    "    return res\n",
    "\n",
    "def plot_average_penalty(airport, years, df):\n",
    "    df = get_average_df(airport, years, df)\n",
    "    title = '{} Airport - Average Penalties'.format(airport)\n",
    "    if df.empty:\n",
    "        print('No data for airport {}'.format(airport))\n",
    "    else:\n",
    "        df.plot.bar(y=airport, title=title, rot=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
