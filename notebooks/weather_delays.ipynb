{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Apache Spark on this machine\n",
    "import findspark\n",
    "findspark.init('/Users/giacomogregori/spark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Build a Spark SQL Session for DataFrames\n",
    "master = 'local[4]'\n",
    "appName = 'Weather delays percentages'\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(appName) \\\n",
    "    .master(master) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "full_data = '../dataset/*.csv.bz2'\n",
    "full_data_parquet = '../dataset/RITA_1994-2008.parquet'\n",
    "\n",
    "path = Path(full_data_parquet)\n",
    "# If reduced dataset is not found, load the full compressed dataset and reduce it.\n",
    "# This is going to take lot of time. Just wait.\n",
    "if not path.is_dir():\n",
    "    df = spark.read.csv(full_data, inferSchema=True, header=True, sep=',')\n",
    "    df.replace('NA', None) \\\n",
    "    .write \\\n",
    "    .save(full_data_parquet, format='parquet')\n",
    "\n",
    "# Load the reduced dataset\n",
    "df = spark.read.load(full_data_parquet, format='parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Year',\n",
       " 'Month',\n",
       " 'DayofMonth',\n",
       " 'DayOfWeek',\n",
       " 'DepTime',\n",
       " 'CRSDepTime',\n",
       " 'ArrTime',\n",
       " 'CRSArrTime',\n",
       " 'UniqueCarrier',\n",
       " 'FlightNum',\n",
       " 'TailNum',\n",
       " 'ActualElapsedTime',\n",
       " 'CRSElapsedTime',\n",
       " 'AirTime',\n",
       " 'ArrDelay',\n",
       " 'DepDelay',\n",
       " 'Origin',\n",
       " 'Dest',\n",
       " 'Distance',\n",
       " 'TaxiIn',\n",
       " 'TaxiOut',\n",
       " 'Cancelled',\n",
       " 'CancellationCode',\n",
       " 'Diverted',\n",
       " 'CarrierDelay',\n",
       " 'WeatherDelay',\n",
       " 'NASDelay',\n",
       " 'SecurityDelay',\n",
       " 'LateAircraftDelay']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+------------+------------+--------+-------------+-----------------+\n",
      "|               Date|WeekYear|CarrierDelay|WeatherDelay|NASDelay|SecurityDelay|LateAircraftDelay|\n",
      "+-------------------+--------+------------+------------+--------+-------------+-----------------+\n",
      "|2007-01-01 00:00:00|       1|           0|           0|       0|            0|                0|\n",
      "|2007-01-01 00:00:00|       1|           0|           0|       0|            0|                0|\n",
      "|2007-01-01 00:00:00|       1|           3|           0|       0|            0|               31|\n",
      "|2007-01-01 00:00:00|       1|          23|           0|       0|            0|                3|\n",
      "|2007-01-01 00:00:00|       1|           0|           0|       0|            0|                0|\n",
      "|2007-01-01 00:00:00|       1|           0|           0|       0|            0|                0|\n",
      "|2007-01-01 00:00:00|       1|          46|           0|       0|            0|                1|\n",
      "|2007-01-01 00:00:00|       1|           0|           0|       0|            0|                0|\n",
      "|2007-01-01 00:00:00|       1|          20|           0|       0|            0|               24|\n",
      "|2007-01-01 00:00:00|       1|           0|           0|       0|            0|                0|\n",
      "+-------------------+--------+------------+------------+--------+-------------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop cancelled flights\n",
    "df = df.drop(df['Cancelled'] == 1)\n",
    "\n",
    "\n",
    "# Parse dates to datetime format\n",
    "import datetime\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import TimestampType, IntegerType\n",
    "\n",
    "make_date = lambda year, month, day : datetime.datetime(year, month, day) \n",
    "make_date = F.udf(make_date, TimestampType())\n",
    "\n",
    "week_year = lambda date : date.isocalendar()[1]\n",
    "week_year = F.udf(week_year, IntegerType())\n",
    "\n",
    "df = df.select(make_date(df['Year'], df['Month'], df['DayofMonth']).alias('Date'), \\\n",
    "               'DayOfWeek', 'CarrierDelay', 'WeatherDelay','NASDelay','SecurityDelay','LateAircraftDelay')\n",
    "df = df.select('Date', week_year('Date').alias('WeekYear'), 'CarrierDelay', 'WeatherDelay','NASDelay','SecurityDelay','LateAircraftDelay')\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+-----+\n",
      "|Year|WeekYear|count|\n",
      "+----+--------+-----+\n",
      "|2008|      35| 1413|\n",
      "|2005|      29| 3018|\n",
      "|2005|      49| 3513|\n",
      "|2007|       6| 2165|\n",
      "|2007|      52| 3271|\n",
      "|2005|       5| 1267|\n",
      "|2007|      28| 2940|\n",
      "|2005|      51| 1584|\n",
      "|2005|      25| 1653|\n",
      "|2008|      28| 3249|\n",
      "+----+--------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Flights that have a WeatherDelay\n",
    "weather_delayed_flights = df.filter(df['WeatherDelay'] > 0)\n",
    "\n",
    "# Flights that have a Delay\n",
    "delayed_flights = df.filter((df['CarrierDelay'] > 0) | (df['WeatherDelay'] > 0) | (df['NASDelay'] > 0) | (df['SecurityDelay'] > 0) | (df['LateAircraftDelay'] > 0)\n",
    "\n",
    "# Number of times per week flights had a weather delay or a general delay  \n",
    "weather_delays = weather_delayed_flights.groupBy([F.year('Date').alias('Year'), 'WeekYear']).count()\n",
    "general_delays = delayed_flights.groupBy([F.year('Date').alias('Year'), 'WeekYear']).count()\n",
    "\n",
    "weather_delays.show(10)\n",
    "general_delays.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
